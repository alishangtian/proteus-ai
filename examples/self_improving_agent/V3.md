**自我进化智能体系统（Self-Improving Agent System）设计构想**

该设计构想描绘了一个基于ReAct范式的智能体如何通过与人、环境的交互实现自我进化，最终成为特定领域专家的系统。

**一、核心概念与运作原理**

1.  **原生形态：** 系统初始为一个典型的ReAct Agent，具备基础的工具集（Tools）和提示词（Prompt）。
2.  **记忆能力：** Agent在交互过程中，会生成并积累不同维度的记忆，这些记忆是其进化的核心驱动力。
    *   **Tool Memory (工具记忆)：** 用于优化Agent对工具的选择和使用。它记录了工具调用的核心要点，指导Agent在面对类似问题时更有效地选择和调用工具。
    *   **SOP Memory (标准操作流程记忆)：** 用于指导Agent更好地生成解决问题的“剧本”（Playbook）。它提炼了问题解决的标准流程，是概括性的指导文本，不涉及具体的工具调用细节。
3.  **进化过程：** Agent通过持续生成和积累Tool Memory和SOP Memory，不断优化其工具选择策略和问题解决剧本生成能力，从而实现自我改进和进化。
4.  **最终目标：** 成为一个能够适应特定语境和环境，解决某一类或某几类问题的专家级智能体。

**二、系统构成与关键组件**

1.  **ReAct Agent：** 整个系统的基础框架，负责推理、行动和观察的循环。
2.  **工具（Tools）：** Agent执行任务所需的功能模块，包括但不限于：
    *   `search_tool` (搜索工具)
    *   `crawler_tool` (爬虫工具)
    *   `python_excutor` (Python执行器)
3.  **记忆模块（Memorys）：** 存储不同类型信息的模块，其生成完全依赖于系统提示词和模型。
    *   `python_excutor_memory`
    *   `search_tool_memory`
    *   `crawler_tool_memory`
    *   `sop_memory`

**三、系统提示词（System Prompts）设计**

系统通过精心设计的提示词来引导Agent生成和利用记忆，实现自我进化。

1.  **`tool_memory` 系统提示词：**
    *   **角色：** 工具选择专家。
    *   **任务：** 根据工具调用详情（`${tool_invoke_text}`）和用户问题（`${query}`），总结调用此工具的核心要点。
    *   **输出：** 生成并输出工具调用的核心要点。

2.  **`playbook` 系统提示词：**
    *   **角色：** 剧本生成专家。
    *   **任务：** 根据用户问题（`${query}`）、工具列表（`${tools}`）、最新工具调用结果（`${tool_invoke_text}`）和历史剧本（`${pre_playbook}`），生成能够解决用户问题的新剧本。
    *   **剧本内容要求：** 必须涵盖以下三部分：
        *   任务规划和完成度。
        *   工具调用要点总结（只提取要素，不进行总结）。
        *   工具调用记录（陈列所有工具调用的情况，不进行总结，只对`observation`进行必要的概括）。
    *   **输出：** 新的剧本。

3.  **`sop` 系统提示词（在一次完整的对话完成后触发）：**
    *   **任务：** 根据用户问题（`${query}`）、剧本（`${playbook}`）和最终结果（`${answer}`），提炼问题解决的标准流程。
    *   **流程特点：** 这是一个指导性的、概括性的文本，不涉及具体的工具调用。
    *   **输出：** 解决用户问题的标准流程。

**四、自我改进与进化路径**

该系统通过以下机制实现自我改进：

*   **经验积累：** Agent在每次任务执行中积累Tool Memory和SOP Memory。
*   **反馈循环：** 记忆的生成和利用形成一个反馈循环，不断优化Agent的决策和行动。
*   **专业化：** 随着记忆的丰富，Agent逐渐在特定领域形成专业知识和解决策略，提升其解决复杂问题的能力。

这个自我进化智能体系统通过ReAct框架、多维度记忆机制和精细的提示词设计，构建了一个能够持续学习、优化和专业化的智能体。它旨在通过与环境的持续交互，从经验中学习，最终成为一个高效、自适应的问题解决专家。

---

**工程实现方案**

**一、系统架构设计**

1.  **核心Agent模块：**
    *   **ReAct Agent Core：** 负责推理、行动、观察循环的调度与执行。
    *   **Prompt Manager：** 动态管理和加载不同类型的提示词（系统提示词、工具提示词、记忆生成提示词等）。
    *   **Tool Orchestrator：** 负责工具的注册、发现、调用和结果处理。

2.  **记忆管理模块：**
    *   **Memory Store：** 统一的记忆存储接口，底层可对接多种存储方案（如向量数据库、关系型数据库、KV存储）。
    *   **Memory Generator：** 根据预设的提示词和Agent的交互数据，生成Tool Memory和SOP Memory。
    *   **Memory Retriever：** 根据当前任务和上下文，从Memory Store中检索相关的Tool Memory和SOP Memory。
    *   **Memory Updater：** 负责记忆的更新、合并、去重和淘汰策略。

3.  **工具模块：**
    *   **Tool Registry：** 注册所有可用工具及其元数据（描述、参数、输出）。
    *   **Tool Adapters：** 将通用工具接口适配到具体工具的调用方式。

4.  **外部接口层：**
    *   **User Interface (UI/API)：** 提供与用户交互的界面或API接口。
    *   **Environment Adapters：** 与外部环境（如操作系统、第三方服务）进行交互的适配器。

**二、关键技术选型**

1.  **大型语言模型 (LLM)：**
    *   **核心推理：** 选用高性能的LLM（如GPT-4、Claude 3、Llama 3等）作为ReAct Agent的核心推理引擎。
    *   **记忆生成：** 同样利用LLM根据特定提示词生成Tool Memory和SOP Memory。

2.  **记忆存储：**
    *   **向量数据库：** 用于存储Tool Memory和SOP Memory的嵌入向量，实现高效的语义检索（如Pinecone, Weaviate, Milvus, Qdrant）。
    *   **关系型数据库/KV存储：** 用于存储记忆的原始文本内容和元数据（如PostgreSQL, Redis）。

3.  **消息队列 (Message Queue)：**
    *   **模块间通信：** 用于解耦Agent核心与记忆管理模块、工具模块之间的通信，实现异步处理和高并发（如Kafka, RabbitMQ, Pulsar）。

4.  **框架与库：**
    *   **Agent框架：** 可以基于LangChain、LlamaIndex等现有框架进行二次开发，或自行构建轻量级框架。
    *   **Web框架：** 用于构建UI/API接口（如FastAPI, Flask, Django）。

**三、数据流转与存储方案**

1.  **数据流转：**
    *   **用户请求：** 用户通过UI/API提交任务。
    *   **Agent处理：** ReAct Agent Core接收请求，根据Playbook进行推理，调用工具。
    *   **记忆生成：** 在工具调用后，Tool Orchestrator将调用详情发送给Memory Generator生成Tool Memory；在任务完成后，Agent将Playbook和最终结果发送给Memory Generator生成SOP Memory。
    *   **记忆检索：** Agent在推理过程中，通过Memory Retriever从Memory Store中检索相关记忆，辅助决策。
    *   **结果返回：** Agent将最终答案返回给用户。

2.  **数据存储：**
    *   **原始交互数据：** 存储Agent与用户、环境的所有交互日志，用于审计和回溯。
    *   **Tool Memory：** 存储工具调用的核心要点，包含原始文本、嵌入向量、关联的用户问题、调用上下文等。
    *   **SOP Memory：** 存储问题解决的标准流程，包含原始文本、嵌入向量、关联的用户问题、Playbook等。
    *   **Playbook历史：** 存储每次任务执行的Playbook，用于SOP Memory的生成和历史回溯。

**四、记忆的生成与管理机制**

1.  **记忆生成：**
    *   **Tool Memory生成：** 每次工具调用成功后，根据`tool_memory`系统提示词，由LLM从`tool_invoke_text`和`query`中提炼核心要点，生成Tool Memory。
    *   **SOP Memory生成：** 在一次完整的对话（任务）完成后，根据`sop`系统提示词，由LLM从`query`、`playbook`和`answer`中提炼标准操作流程，生成SOP Memory。

2.  **记忆管理：**
    *   **去重与合并：** 对于相似或重复的记忆，进行去重或合并，避免冗余。
    *   **版本控制：** 对记忆进行版本管理，允许回溯和比较不同版本的记忆。
    *   **淘汰机制：** 根据记忆的使用频率、时效性等策略，定期淘汰低价值记忆。
    *   **评估与优化：** 定期评估记忆的质量和有效性，通过人工标注或Agent自评估来优化记忆生成策略。

**五、模块间通信机制**

1.  **同步通信：**
    *   **Agent核心与工具调用：** ReAct Agent Core通过Tool Orchestrator同步调用工具，等待结果返回。
    *   **Agent核心与记忆检索：** Agent在推理时同步调用Memory Retriever获取相关记忆。

2.  **异步通信：**
    *   **记忆生成：** 工具调用结果和任务完成事件通过消息队列异步发送给Memory Generator，避免阻塞Agent核心。
    *   **记忆更新：** Memory Updater对记忆的去重、合并、淘汰等操作可以异步进行。

**六、持续优化与进化**

1.  **A/B测试：** 对不同的记忆生成策略、检索算法进行A/B测试，评估效果。
2.  **人工反馈：** 引入人工标注和反馈机制，对Agent的决策和记忆质量进行监督和修正。
3.  **自监督学习：** Agent可以根据任务的成功率、效率等指标，自我评估记忆的有效性，并调整记忆生成和利用策略。
4.  **领域适应：** 针对特定领域，通过领域知识注入和微调，加速Agent在该领域的专业化进程。

**优化与工程实现方案**

**一、系统架构设计**

1.  **核心Agent模块：**
    *   **ReAct Agent Core：** 负责推理、行动、观察循环的调度与执行。
    *   **Prompt Manager：** 动态管理和加载不同类型的提示词（系统提示词、工具提示词、记忆生成提示词等）。
    *   **Tool Orchestrator：** 负责工具的注册、发现、调用和结果处理。

2.  **记忆管理模块：**
    *   **Memory Store：** 统一的记忆存储接口，底层可对接多种存储方案（如向量数据库、关系型数据库、KV存储）。
    *   **Memory Generator：** 根据预设的提示词和Agent的交互数据，生成Tool Memory和SOP Memory。
    *   **Memory Retriever：** 根据当前任务和上下文，从Memory Store中检索相关的Tool Memory和SOP Memory。
    *   **Memory Updater：** 负责记忆的更新、合并、去重和淘汰策略。

3.  **工具模块：**
    *   **Tool Registry：** 注册所有可用工具及其元数据（描述、参数、输出）。
    *   **Tool Adapters：** 将通用工具接口适配到具体工具的调用方式。

4.  **外部接口层：**
    *   **User Interface (UI/API)：** 提供与用户交互的界面或API接口。
    *   **Environment Adapters：** 与外部环境（如操作系统、第三方服务）进行交互的适配器。

**二、关键技术选型**

1.  **大型语言模型 (LLM)：**
    *   **核心推理：** 选用高性能的LLM（如GPT-4、Claude 3、Llama 3等）作为ReAct Agent的核心推理引擎。
    *   **记忆生成：** 同样利用LLM根据特定提示词生成Tool Memory和SOP Memory。

2.  **记忆存储：**
    *   **向量数据库：** 用于存储Tool Memory和SOP Memory的嵌入向量，实现高效的语义检索（如Pinecone, Weaviate, Milvus, Qdrant）。
    *   **关系型数据库/KV存储：** 用于存储记忆的原始文本内容和元数据（如PostgreSQL, Redis）。

3.  **消息队列 (Message Queue)：**
    *   **模块间通信：** 用于解耦Agent核心与记忆管理模块、工具模块之间的通信，实现异步处理和高并发（如Kafka, RabbitMQ, Pulsar）。

4.  **框架与库：**
    *   **Agent框架：** 可以基于LangChain、LlamaIndex等现有框架进行二次开发，或自行构建轻量级框架。
    *   **Web框架：** 用于构建UI/API接口（如FastAPI, Flask, Django）。

**三、数据流转与存储方案**

1.  **数据流转：**
    *   **用户请求：** 用户通过UI/API提交任务。
    *   **Agent处理：** ReAct Agent Core接收请求，根据Playbook进行推理，调用工具。
    *   **记忆生成：** 在工具调用后，Tool Orchestrator将调用详情发送给Memory Generator生成Tool Memory；在任务完成后，Agent将Playbook和最终结果发送给Memory Generator生成SOP Memory。
    *   **记忆检索：** Agent在推理过程中，通过Memory Retriever从Memory Store中检索相关记忆，辅助决策。
    *   **结果返回：** Agent将最终答案返回给用户。

2.  **数据存储：**
    *   **原始交互数据：** 存储Agent与用户、环境的所有交互日志，用于审计和回溯。
    *   **Tool Memory：** 存储工具调用的核心要点，包含原始文本、嵌入向量、关联的用户问题、调用上下文等。
    *   **SOP Memory：** 存储问题解决的标准流程，包含原始文本、嵌入向量、关联的用户问题、Playbook等。
    *   **Playbook历史：** 存储每次任务执行的Playbook，用于SOP Memory的生成和历史回溯。

**四、记忆的生成与管理机制**

1.  **记忆生成：**
    *   **Tool Memory生成：** 每次工具调用成功后，根据`tool_memory`系统提示词，由LLM从`tool_invoke_text`和`query`中提炼核心要点，生成Tool Memory。
    *   **SOP Memory生成：** 在一次完整的对话（任务）完成后，根据`sop`系统提示词，由LLM从`query`、`playbook`和`answer`中提炼标准操作流程，生成SOP Memory。

2.  **记忆管理：**
    *   **去重与合并：** 对于相似或重复的记忆，进行去重或合并，避免冗余。
    *   **版本控制：** 对记忆进行版本管理，允许回溯和比较不同版本的记忆。
    *   **淘汰机制：** 根据记忆的使用频率、时效性等策略，定期淘汰低价值记忆。
    *   **评估与优化：** 定期评估记忆的质量和有效性，通过人工标注或Agent自评估来优化记忆生成策略。

**五、模块间通信机制**

1.  **同步通信：**
    *   **Agent核心与工具调用：** ReAct Agent Core通过Tool Orchestrator同步调用工具，等待结果返回。
    *   **Agent核心与记忆检索：** Agent在推理时同步调用Memory Retriever获取相关记忆。

2.  **异步通信：**
    *   **记忆生成：** 工具调用结果和任务完成事件通过消息队列异步发送给Memory Generator，避免阻塞Agent核心。
    *   **记忆更新：** Memory Updater对记忆的去重、合并、淘汰等操作可以异步进行。

**六、持续优化与进化**

1.  **A/B测试：** 对不同的记忆生成策略、检索算法进行A/B测试，评估效果。
2.  **人工反馈：** 引入人工标注和反馈机制，对Agent的决策和记忆质量进行监督和修正。
3.  **自监督学习：** Agent可以根据任务的成功率、效率等指标，自我评估记忆的有效性，并调整记忆生成和利用策略。
4.  **领域适应：** 针对特定领域，通过领域知识注入和微调，加速Agent在该领域的专业化进程。

**七、具体的代码实现示例 (Python)**

以下提供一个简化的Python代码示例，展示核心模块的实现思路。这只是一个概念验证，实际生产环境需要更完善的错误处理、并发控制、持久化存储等。

```python
import uuid
import time
from typing import Dict, Any, List, Callable, Optional

# --- 1. LLM Client (模拟) ---
class MockLLMClient:
    """模拟LLM客户端，用于生成Thought、Action和Memory。"""
    def generate(self, prompt: str, **kwargs) -> str:
        print(f"--- LLM Generating with Prompt ---\n{prompt}\n--------------------------------")
        # 实际应用中这里会调用真实的LLM API
        if "Thought:" in prompt and "Action:" in prompt:
            # 模拟ReAct Agent的输出
            if "Playbook中的所有任务都已完成" in prompt:
                return "Thought: 所有必要的任务均已完成。我已经收集到了足够的信息，现在可以生成最终答案。\nAnswer: 这是一个模拟的最终答案，基于所有已完成的任务和观察结果。"
            elif "serper_search" in prompt:
                return "Thought: 我需要搜索最新的信息来回答用户问题。为了实现这个目标，我需要调用 serper_search 工具来获取相关网页内容。\nAction: serper_search\nAction Input: {\"query\": \"最新科技新闻\"}"
            elif "web_crawler" in prompt:
                return "Thought: 我已经找到了一个相关的网页链接，现在需要爬取其内容。为了实现这个目标，我需要调用 web_crawler 工具来获取网页正文。\nAction: web_crawler\nAction Input: {\"url\": \"https://example.com/news\", \"need_summary\": true}"
            else:
                return "Thought: 我需要执行一个Python代码片段。为了实现这个目标，我需要调用 python_execute 工具来运行代码。\nAction: python_execute\nAction Input: {\"code\": \"print('Hello from Python!')\", \"language\": \"python\", \"enable_network\": false}"
        elif "总结调用此工具的核心要点" in prompt:
            return f"Tool Memory: 核心要点 - {kwargs.get('tool_name', 'unknown')} 被调用以处理 {kwargs.get('query', '未知查询')}，结果是 {kwargs.get('observation', '无')[:50]}..."
        elif "提炼问题解决的标准流程" in prompt:
            return f"SOP Memory: 解决 {kwargs.get('query', '未知问题')} 的标准流程：{kwargs.get('playbook', '无剧本')} -> {kwargs.get('answer', '无答案')[:50]}..."
        return "Mock LLM Response."

# --- 2. Tool Registry and Orchestrator (简化版) ---
class Tool:
    def __init__(self, name: str, description: str, parameters: Dict, func: Callable):
        self.name = name
        self.description = description
        self.parameters = parameters
        self.func = func

    def __call__(self, **kwargs) -> Dict:
        try:
            result = self.func(**kwargs)
            return {"result": result, "success": True}
        except Exception as e:
            return {"stderr": str(e), "success": False}

class ToolOrchestrator:
    def __init__(self):
        self.tools: Dict[str, Tool] = {}

    def register_tool(self, tool: Tool):
        self.tools[tool.name] = tool

    def get_tool_description(self) -> str:
        descriptions = []
        for name, tool in self.tools.items():
            descriptions.append(f"## {tool.name}\n**Description**: {tool.description}\n**Parameters**: {tool.parameters}")
        return "\n\n".join(descriptions)

    def execute_tool(self, tool_name: str, tool_input: Dict) -> Dict:
        if tool_name not in self.tools:
            return {"stderr": f"Tool '{tool_name}' not found.", "success": False}
        print(f"Executing tool: {tool_name} with input: {tool_input}")
        return self.tools[tool_name](**tool_input)

# --- 3. Memory Store (简化版，内存存储) ---
class MemoryStore:
    def __init__(self):
        self.tool_memories: List[Dict] = []
        self.sop_memories: List[Dict] = []
        # 实际应用中会使用向量数据库进行语义检索
        self.vector_db_mock = {} # {embedding_vector: memory_content}

    def add_tool_memory(self, memory_content: str, query: str, tool_name: str, observation: str):
        memory = {
            "id": str(uuid.uuid4()),
            "type": "tool",
            "content": memory_content,
            "query": query,
            "tool_name": tool_name,
            "observation": observation,
            "timestamp": time.time()
        }
        self.tool_memories.append(memory)
        # 模拟向量存储
        self.vector_db_mock[hash(memory_content) % 1000] = memory # 简化哈希作为embedding
        print(f"Added Tool Memory: {memory_content[:100]}...")

    def add_sop_memory(self, memory_content: str, query: str, playbook: str, answer: str):
        memory = {
            "id": str(uuid.uuid4()),
            "type": "sop",
            "content": memory_content,
            "query": query,
            "playbook": playbook,
            "answer": answer,
            "timestamp": time.time()
        }
        self.sop_memories.append(memory)
        # 模拟向量存储
        self.vector_db_mock[hash(memory_content) % 1000] = memory
        print(f"Added SOP Memory: {memory_content[:100]}...")

    def retrieve_tool_memories(self, query: str, top_k: int = 3) -> List[Dict]:
        # 实际应用中会进行语义相似度检索
        print(f"Retrieving Tool Memories for query: {query}")
        # 模拟检索，返回最近的k个
        return sorted(self.tool_memories, key=lambda x: x['timestamp'], reverse=True)[:top_k]

    def retrieve_sop_memories(self, query: str, top_k: int = 1) -> List[Dict]:
        # 实际应用中会进行语义相似度检索
        print(f"Retrieving SOP Memories for query: {query}")
        # 模拟检索，返回最近的k个
        return sorted(self.sop_memories, key=lambda x: x['timestamp'], reverse=True)[:top_k]

# --- 4. Prompt Manager ---
class PromptManager:
    def __init__(self):
        self.prompts = {
            "tool_memory_prompt": """
                你是一个工具选择专家。
                根据工具调用详情：`{tool_invoke_text}` 和用户问题：`{query}`，总结调用此工具的核心要点。
                输出：生成并输出工具调用的核心要点。
            """,
            "sop_memory_prompt": """
                你是一个流程提炼专家。
                根据用户问题：`{query}`、剧本：`{playbook}` 和最终结果：`{answer}`，提炼问题解决的标准流程。
                流程特点：这是一个指导性的、概括性的文本，不涉及具体的工具调用。
                输出：解决用户问题的标准流程。
            """,
            "react_agent_prompt_template": """
                # 📜 使命与身份
                你是 Proteus，一个由大型语言模型驱动的、基于 ReAct 范式的顶尖智能代理。
                你的核心使命是精确、高效地完成复杂任务。

                ---

                # 🌟 Playbook：任务执行的唯一剧本
                **Playbook 是整个任务的核心，是你所有思考和行动的唯一依据和最终指南。** 它包含了为了完成最终目标而必须执行的所有子任务列表。

                - **核心地位**: Playbook 是任务的“唯一事实来源”（Single Source of Truth）。你**必须**严格按照 Playbook 的指引，依次完成其中定义的每一个子任务。
                - **决策依据**: 你的每一步推理（Thought）和工具调用（Action）都**必须**以 Playbook 中的待办任务为出发点。
                - **任务步骤**: 每一个待办任务都可能会需要多步工具调用才能实现，请仔细审视待办项是否真的完成。
                - **完成标志**: 只有当 Playbook 中所有的任务都标记为完成时，你才能认为最终目标已达成，并可以生成最终答案（Answer）。

                ---

                # 🎯 核心工作流：ReAct 循环
                你通过「Thought -> Action -> Observation」的迭代循环来解决问题。每一次循环都必须严格遵循以下指引：

                1.  **第一步：聚焦 Playbook**
                    - 在每一次循环开始时，**必须**首先审视当前的 `Playbook`，识别出下一个需要执行的子任务。

                2.  **第二步：思考（Thought）**
                    - 基于当前需要完成的任务，进行简明扼要的推理。说明你为什么选择某个工具来完成这个特定的任务。
                    - **注意**: 在 Thought 中只需要描述要完成的事情和选择工具的理由，不要提及 Playbook 或其他参考内容。

                3.  **第三步：行动（Action）**
                    - **精准选型**: 从下方 `可用工具列表` 中选择最适合当前子任务的工具。
                    - **原子操作**: 每次循环**只能**调用一个工具。

                4.  **第四步：观察（Observation）**
                    - 系统会返回工具执行的结果，这是你进行下一步决策的关键信息。

                5.  **循环与终止**
                    - **迭代**: 持续这个循环，直到 `Playbook` 中的所有任务都完成。
                    - **终止**: 当 `Playbook` 完成后，进入“最终答案模式”，总结所有 `Observation`，并参照 `Playbook` 的目标给出最终答案。
                    - **用户干预**: 如果工具执行多次失败或陷入困境，应主动向用户求助。

                ---

                # 🛠️ 可用工具列表
                {tool_descriptions}

                ---

                # ⚡ 输出格式规范（至关重要）
                你**必须**严格遵循以下两种格式之一进行输出，不得有任何偏差。

                ## 格式一：工具调用模式
                ```
                Thought: 我需要 `[描述要完成的事情]`。为了实现这个目标，我需要调用 `[工具名称]` 工具来 `[说明原因]`。
                Action: [工具名称]
                Action Input: {{"参数名": "参数值", ...}}
                ```

                ## 格式二：最终答案模式
                ```
                Thought: 所有必要的任务均已完成。我已经收集到了足够的信息，现在可以生成最终答案。
                Answer: [直接给出一个详尽、完整、包含关键信息的最终答案，只输出满足用户问题的答案内容，不要提及参考了什么内容或完成了什么任务。]
                ```

                ---

                # 📝 关键上下文信息
                - **行为指引**: 
                - **附加上下文**: 暂无
                - **当前时间**: {current_time}

                ---

                # 🚀 开始执行

                ## Playbook (任务剧本)
                {playbook}

                ## 历史交互记录
                {history}
                """
        }

    def get_prompt(self, name: str, **kwargs) -> str:
        template = self.prompts.get(name)
        if not template:
            raise ValueError(f"Prompt '{name}' not found.")
        return template.format(**kwargs)

# --- 5. ReAct Agent Core ---
class ReActAgent:
    def __init__(self, llm_client: MockLLMClient, tool_orchestrator: ToolOrchestrator,
                 memory_store: MemoryStore, prompt_manager: PromptManager):
        self.llm_client = llm_client
        self.tool_orchestrator = tool_orchestrator
        self.memory_store = memory_store
        self.prompt_manager = prompt_manager
        self.history: List[str] = []
        self.playbook: Dict = {
            "第一部分：任务规划与完成度": {"任务列表": [], "关联性判断": "", "状态更新": {}},
            "第二部分：关键信息汇总": {},
            "第三部分：完整调用过程": []
        }
        self.current_query: str = ""
        self.final_answer: Optional[str] = None

    def _update_playbook_status(self, task_description: str, status: bool = True):
        # 简化更新逻辑，实际可能需要更复杂的匹配
        for i, task in enumerate(self.playbook["第一部分：任务规划与完成度"]["任务列表"]):
            if task_description in task:
                if status:
                    self.playbook["第一部分：任务规划与完成度"]["任务列表"][i] = task.replace("[ ]", "[x]")
                else:
                    self.playbook["第一部分：任务规划与完成度"]["任务列表"][i] = task.replace("[x]", "[ ]")
                break
        # 状态更新也需要同步
        self.playbook["第一部分：任务规划与完成度"]["状态更新"][task_description] = "[x]" if status else "[ ]"

    def _parse_llm_output(self, output: str) -> Dict[str, Any]:
        thought_match = re.search(r"Thought: (.*)", output)
        action_match = re.search(r"Action: (\w+)", output)
        action_input_match = re.search(r"Action Input: (\{.*\})", output, re.DOTALL)
        answer_match = re.search(r"Answer: (.*)", output, re.DOTALL)

        parsed = {}
        if thought_match:
            parsed["thought"] = thought_match.group(1).strip()
        if action_match:
            parsed["action"] = action_match.group(1).strip()
        if action_input_match:
            try:
                parsed["action_input"] = json.loads(action_input_match.group(1).strip())
            except json.JSONDecodeError:
                print(f"Warning: Could not parse Action Input JSON: {action_input_match.group(1)}")
                parsed["action_input"] = {}
        if answer_match:
            parsed["answer"] = answer_match.group(1).strip()
        return parsed

    def run(self, initial_query: str, initial_playbook_tasks: List[str]):
        self.current_query = initial_query
        self.playbook["第一部分：任务规划与完成度"]["任务列表"] = [f"[ ] {task}" for task in initial_playbook_tasks]
        self.playbook["第一部分：任务规划与完成度"]["状态更新"] = {task: "[ ]" for task in initial_playbook_tasks}
        self.playbook["第二部分：关键信息汇总"]["用户问题"] = initial_query

        print(f"Agent started with query: {initial_query}")
        print(f"Initial Playbook: {self.playbook['第一部分：任务规划与完成度']['任务列表']}")

        max_iterations = 10 # 防止无限循环
        iteration = 0

        while iteration < max_iterations:
            iteration += 1
            print(f"\n--- Iteration {iteration} ---")

            # 1. 聚焦 Playbook，识别下一个待执行任务
            next_task = None
            for task_item in self.playbook["第一部分：任务规划与完成度"]["任务列表"]:
                if "[ ]" in task_item:
                    next_task = task_item.replace("[ ] ", "")
                    break
            
            if not next_task and not self.final_answer: # 所有任务都完成了，进入最终答案模式
                print("All playbook tasks completed. Generating final answer.")
                prompt = self.prompt_manager.get_prompt(
                    "react_agent_prompt_template",
                    tool_descriptions=self.tool_orchestrator.get_tool_description(),
                    playbook=json.dumps(self.playbook, indent=2, ensure_ascii=False),
                    history="\n".join(self.history),
                    current_time=time.strftime("%Y-%m-%d %H:%M:%S")
                )
                llm_output = self.llm_client.generate(prompt)
                parsed_output = self._parse_llm_output(llm_output)
                if "answer" in parsed_output:
                    self.final_answer = parsed_output["answer"]
                    print(f"Final Answer: {self.final_answer}")
                    # 生成SOP Memory
                    sop_prompt = self.prompt_manager.get_prompt(
                        "sop_memory_prompt",
                        query=self.current_query,
                        playbook=json.dumps(self.playbook, indent=2, ensure_ascii=False),
                        answer=self.final_answer
                    )
                    sop_memory_content = self.llm_client.generate(sop_prompt, query=self.current_query, playbook=json.dumps(self.playbook, indent=2, ensure_ascii=False), answer=self.final_answer)
                    self.memory_store.add_sop_memory(sop_memory_content, self.current_query, json.dumps(self.playbook, indent=2, ensure_ascii=False), self.final_answer)
                    break # 任务完成，退出循环
                else:
                    print("Error: Expected final answer but got no answer from LLM.")
                    break

            if not next_task: # 理论上应该在上面被捕获，这里是双重检查
                print("No pending tasks in playbook, but no final answer generated. Exiting.")
                break

            # 2. 思考 (Thought) 和 3. 行动 (Action)
            current_prompt = self.prompt_manager.get_prompt(
                "react_agent_prompt_template",
                tool_descriptions=self.tool_orchestrator.get_tool_description(),
                playbook=json.dumps(self.playbook, indent=2, ensure_ascii=False),
                history="\n".join(self.history),
                current_time=time.strftime("%Y-%m-%d %H:%M:%S")
            )
            llm_output = self.llm_client.generate(current_prompt)
            parsed_output = self._parse_llm_output(llm_output)

            if "thought" in parsed_output:
                print(f"Thought: {parsed_output['thought']}")
                self.history.append(f"Thought: {parsed_output['thought']}")
            else:
                print("Error: LLM did not provide a Thought. Exiting.")
                break

            if "action" in parsed_output and "action_input" in parsed_output:
                tool_name = parsed_output["action"]
                tool_input = parsed_output["action_input"]
                print(f"Action: {tool_name}")
                print(f"Action Input: {tool_input}")
                self.history.append(f"Action: {tool_name}")
                self.history.append(f"Action Input: {tool_input}")

                # 4. 观察 (Observation)
                tool_result = self.tool_orchestrator.execute_tool(tool_name, tool_input)
                observation = tool_result.get("result") or tool_result.get("stderr")
                success = tool_result.get("success", False)
                print(f"Observation: {observation}")
                self.history.append(f"Observation: {observation}")
                self.playbook["第三部分：完整调用过程"].append({
                    "thought": parsed_output['thought'],
                    "action": tool_name,
                    "action_input": tool_input,
                    "observation": observation,
                    "success": success
                })

                # 生成Tool Memory
                tool_invoke_text = f"Tool: {tool_name}, Input: {tool_input}, Output: {observation}"
                tool_memory_prompt = self.prompt_manager.get_prompt(
                    "tool_memory_prompt",
                    tool_invoke_text=tool_invoke_text,
                    query=self.current_query,
                    tool_name=tool_name,
                    observation=observation
                )
                tool_memory_content = self.llm_client.generate(tool_memory_prompt, tool_invoke_text=tool_invoke_text, query=self.current_query, tool_name=tool_name, observation=observation)
                self.memory_store.add_tool_memory(tool_memory_content, self.current_query, tool_name, observation)

                # 更新Playbook状态 (简化逻辑，实际需要更智能的判断)
                if success:
                    self._update_playbook_status(next_task, True)
                else:
                    print(f"Tool '{tool_name}' failed. Consider re-trying or asking for user input.")
                    # 实际中可能需要更复杂的错误处理和重试机制
                    break # 简化处理，工具失败则退出

            else:
                print("Error: LLM did not provide a valid Action. Exiting.")
                break
        
        if not self.final_answer:
            print("Agent finished without generating a final answer (max iterations reached or error).")
        
        return self.final_answer, self.playbook

# --- 辅助工具函数 ---
def mock_python_execute(code: str, language: str, enable_network: bool, variables: Dict = {}) -> str:
    if language == "python":
        try:
            # 模拟Python执行环境
            _globals = {"print": lambda x: x, **variables} # 简化print，并注入变量
            _locals = {}
            exec(code, _globals, _locals)
            return _globals.get("result", "Python code executed successfully (mock).")
        except Exception as e:
            return f"Python execution error: {e}"
    elif language == "shell":
        return f"Shell command '{code}' executed successfully (mock)."
    return "Unsupported language."

def mock_serper_search(query: str, country: str = "cn", language: str = "zh", max_results: int = 10) -> str:
    return f"Mock search results for '{query}': [Link1 - Summary1], [Link2 - Summary2]"

def mock_web_crawler(url: str, need_summary: bool = False, include_markdown: bool = False) -> str:
    if "example.com/news" in url:
        return "Mock content from example.com/news: This is a summary of the news article." if need_summary else "Full article content from example.com/news."
    return f"Mock content for {url}."

def mock_user_input(prompt: str, input_type: str, default_value: Optional[str] = None, validation: Dict = {}) -> str:
    print(f"User Input Request: {prompt} (Type: {input_type})")
    return default_value if default_value else "Mock user input."

# --- 系统初始化与运行 ---
if __name__ == "__main__":
    import json
    import re

    # 初始化核心组件
    llm_client = MockLLMClient()
    tool_orchestrator = ToolOrchestrator()
    memory_store = MemoryStore()
    prompt_manager = PromptManager()

    # 注册工具
    tool_orchestrator.register_tool(Tool("python_execute", "通用代码执行节点", {"code": "str", "language": "str", "enable_network": "bool", "variables": "dict"}, mock_python_execute))
    tool_orchestrator.register_tool(Tool("serper_search", "Serper搜索引擎节点", {"query": "str", "country": "str", "language": "str", "max_results": "int"}, mock_serper_search))
    tool_orchestrator.register_tool(Tool("web_crawler", "接收URL并返回网页正文内容的节点", {"url": "str", "need_summary": "bool", "include_markdown": "bool"}, mock_web_crawler))
    tool_orchestrator.register_tool(Tool("user_input", "用户输入节点", {"prompt": "str", "input_type": "str", "default_value": "str", "validation": "dict"}, mock_user_input))

    # 创建Agent
    agent = ReActAgent(llm_client, tool_orchestrator, memory_store, prompt_manager)

    # 定义初始任务
    initial_query = "请帮我查找关于2024年人工智能领域最新的突破性进展，并总结其主要内容。"
    initial_playbook_tasks = [
        "使用搜索引擎查找2024年人工智能领域的最新突破性进展。",
        "根据搜索结果，选择至少3篇高质量文章进行内容爬取和总结。",
        "综合所有文章的总结，提炼出2024年人工智能领域的主要突破性进展。",
        "生成最终的报告。"
    ]

    # 运行Agent
    final_answer, final_playbook = agent.run(initial_query, initial_playbook_tasks)

    print("\n--- Agent Run Completed ---")
    print(f"Final Answer: {final_answer}")
    print("\n--- Final Playbook ---")
    print(json.dumps(final_playbook, indent=2, ensure_ascii=False))
    print("\n--- Stored Tool Memories ---")
    for mem in memory_store.tool_memories:
        print(f"- {mem['content']}")
    print("\n--- Stored SOP Memories ---")
    for mem in memory_store.sop_memories:
        print(f"- {mem['content']}")
```

**代码实现说明：**

1.  **`MockLLMClient`：** 模拟了与大型语言模型的交互。在实际应用中，这里会替换为调用OpenAI、Anthropic或其他LLM提供商的API。它根据输入提示词模拟生成Thought/Action或Memory内容。
2.  **`Tool` 和 `ToolOrchestrator`：** `Tool` 类封装了每个工具的元数据和执行函数。`ToolOrchestrator` 负责注册和管理所有工具，并提供统一的工具执行接口。
3.  **`MemoryStore`：** 简化版的记忆存储，使用Python列表模拟存储Tool Memory和SOP Memory。在生产环境中，这会是一个与向量数据库（如Pinecone, Weaviate）和关系型数据库（如PostgreSQL）集成的模块，用于高效的语义检索和持久化存储。
4.  **`PromptManager`：** 集中管理所有系统提示词模板，方便动态加载和格式化。
5.  **`ReActAgent`：** 核心Agent逻辑，实现了ReAct循环。
    *   `run` 方法驱动整个任务执行流程。
    *   `_update_playbook_status` 简化了Playbook任务状态的更新。
    *   `_parse_llm_output` 解析LLM的输出，提取Thought、Action、Action Input或Answer。
    *   在每次工具调用后，会触发Tool Memory的生成。
    *   在任务完成后，会触发SOP Memory的生成。
6.  **`mock_*` 函数：** 模拟了实际工具（`python_execute`, `serper_search`, `web_crawler`, `user_input`）的功能，以便在没有实际外部依赖的情况下运行示例。
7.  **主执行块 (`if __name__ == "__main__":`)：** 演示了如何初始化系统组件，注册工具，创建Agent，并运行一个示例任务。

**进一步优化和完善方向：**

*   **真正的LLM集成：** 将`MockLLMClient`替换为实际的LLM API调用。
*   **向量数据库集成：** `MemoryStore`应与向量数据库（如`chromadb`, `faiss`, `pinecone`等）集成，实现高效的语义检索。
*   **异步处理：** 使用`asyncio`和消息队列（如`Celery` + `Redis/RabbitMQ`）实现记忆生成和更新的异步化，提高Agent的响应速度。
*   **错误处理和重试机制：** 增加更健壮的错误处理、重试策略和用户干预机制。
*   **Playbook的动态生成与优化：** 引入LLM来动态生成和优化Playbook，而不仅仅是预设。
*   **记忆的评估与淘汰：** 实现记忆的质量评估和基于LRU、LFU或语义相关性的淘汰策略。
*   **用户界面/API：** 构建一个Web界面或API接口，方便用户与Agent交互。
*   **监控与日志：** 完善日志记录和监控系统，以便追踪Agent的行为和性能。
*   **安全性：** 特别是`python_execute`工具，需要严格的沙箱机制来防止恶意代码执行。